{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble as ens\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import calendar  # Ahh, importing the weekdays"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import data from .csv file\n",
    "traffic_data = pd.read_csv(\"data.csv\")\n",
    "print(traffic_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot all the total traffic per hour over time to give a holistic impression of the data\n",
    "y_volum_totalt = traffic_data['Volum totalt']\n",
    "x_data_index = list(range(0, len(y_volum_totalt)))\n",
    "fig = plt.figure(figsize=(100,10))\n",
    "plt.plot(x_data_index, y_volum_totalt)\n",
    "plt.show()\n",
    "#It looks like there is a tendency for the traffic to slow down at around the same time each year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Let us have a look at the individual years\n",
    "year_2015 = traffic_data[traffic_data['År'] == 2015]\n",
    "year_2016 = traffic_data[traffic_data['År'] == 2016]\n",
    "year_2017 = traffic_data[traffic_data['År'] == 2017]\n",
    "year_2018 = traffic_data[traffic_data['År'] == 2018]\n",
    "year_2019 = traffic_data[traffic_data['År'] == 2019]\n",
    "\n",
    "print(\"Length of data from 2015:\", len(year_2015))\n",
    "print(\"Length of data from 2016:\", len(year_2016))\n",
    "print(\"Length of data from 2017:\", len(year_2017))\n",
    "print(\"Length of data from 2018:\", len(year_2018))\n",
    "print(\"Length of data from 2019:\", len(year_2019))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#We can see that the data size is not identical for each year, ie we don't have a value for the traffic at every hour for every year.\n",
    "#However 2016-2019 seem to have about the same amount of data\n",
    "def plot_traffic_data_for_year(year_string, year_data):\n",
    "    x = list(range(0, len(year_data)))\n",
    "    y = year_data['Volum totalt']\n",
    "    plt.plot(x,y)\n",
    "    plt.title(year_string)\n",
    "    plt.show()\n",
    "    \n",
    "plot_traffic_data_for_year(\"2015\", year_2015)\n",
    "plot_traffic_data_for_year(\"2016\", year_2016)\n",
    "plot_traffic_data_for_year(\"2017\", year_2017)\n",
    "plot_traffic_data_for_year(\"2018\", year_2018)\n",
    "plot_traffic_data_for_year(\"2019\", year_2019)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Since it is a bit difficult to tell the average traffic per day with the data represented like this, we can try to get total traffic per day instead of per hour\n",
    "\n",
    "def get_total_traffic_per_day(traffic_data):\n",
    "    \"\"\"\n",
    "    Gernerates a list of total traffic per day, where the index corresponds to the day number +1.\n",
    "    \n",
    "    :param traffic_data: dataframe of traffic data, or a subset of the dataframe (fex data for a year)\n",
    "    \"\"\"\n",
    "    totat_traffic_per_day = np.ones(367)\n",
    "    for i in range(len(traffic_data)):\n",
    "        hour_datapoint = traffic_data.iloc[i]\n",
    "        month_number = hour_datapoint[1]\n",
    "        day_number = hour_datapoint[2]\n",
    "        day_of_the_year = datetime.datetime(2016, month_number, day_number).timetuple().tm_yday #retrieve day number\n",
    "        totat_traffic_per_day[day_of_the_year] += hour_datapoint[6] #add traffic that hour to the total traffic per day\n",
    "    return totat_traffic_per_day\n",
    "\n",
    "#generate lists of total traffic per day for the years\n",
    "total_traffic_per_day_2016 = get_total_traffic_per_day(year_2016)\n",
    "total_traffic_per_day_2017 = get_total_traffic_per_day(year_2017)\n",
    "total_traffic_per_day_2018 = get_total_traffic_per_day(year_2018)\n",
    "total_traffic_per_day_2019 = get_total_traffic_per_day(year_2019)\n",
    "\n",
    "x_days_total = list(range(0, len(total_traffic_per_day_2016)))\n",
    "\n",
    "\n",
    "#plotting the traffic pr day\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(x_days_total,total_traffic_per_day_2016, 'r-', alpha = 0.7, label = \"2016\")\n",
    "plt.plot(x_days_total,total_traffic_per_day_2017, 'b-', alpha = 0.7, label = \"2017\")\n",
    "plt.plot(x_days_total,total_traffic_per_day_2018, 'g-', alpha = 0.7, label = \"2018\")\n",
    "plt.plot(x_days_total,total_traffic_per_day_2019, 'y-', alpha = 0.7, label = \"2019\")\n",
    "plt.title(\"Total traffic per day\")\n",
    "plt.xticks(np.arange(min(x_days_total), max(x_days_total)+1, 25))\n",
    "plt.xlabel(\"Day of the year\")\n",
    "plt.ylabel(\"Total traffic per day\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we can se a consistent trend, we would like to extract a bit more information from the data, such as the day of the year and what weekday each datapoint has. Therefore we construct a list of the traffic data represented in datetime format."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datetime_representation_of_today = datetime.datetime.today()\n",
    "print(\"Datetime representation of today:\", datetime_representation_of_today)\n",
    "\n",
    "def generate_datetime_array_from_traffic_data(traffic_data_input):\n",
    "    #initialize np array to store datetime of each datapoint in traffic_data\n",
    "    traffic_data_datetime = np.full(len(traffic_data_input), datetime_representation_of_today)\n",
    "    for i in range(len(traffic_data_input)):\n",
    "        data_point = traffic_data_input.iloc[i]\n",
    "        datetime_representation_of_datapoint = datetime.datetime(data_point[0], data_point[1], data_point[2],data_point[3])\n",
    "        traffic_data_datetime[i] = datetime_representation_of_datapoint\n",
    "    return traffic_data_datetime\n",
    "\n",
    "traffic_data_datetime = generate_datetime_array_from_traffic_data(traffic_data)\n",
    "print(\"Datetime represenation of traffic data:\")\n",
    "print(traffic_data_datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#It is still a bit distracting to see the fluctuation between weekends and weekdays, so we'll take total traffic per week\n",
    "\n",
    "def get_total_traffic_per_week(traffic_data):\n",
    "    \"\"\"\n",
    "    Gernerates a list of total traffic per day, where the index corresponds to the day number +1.\n",
    "    \n",
    "    :param traffic_data: dataframe of traffic data, or a subset of the dataframe (fex data for a year)\n",
    "    \"\"\"\n",
    "    total_traffic_per_week = np.ones(54)\n",
    "    for i in range(len(traffic_data)):\n",
    "        hour_datapoint = traffic_data.iloc[i]\n",
    "        year_number = hour_datapoint[0]\n",
    "        month_number = hour_datapoint[1]\n",
    "        day_number = hour_datapoint[2]\n",
    "        week_number = datetime.datetime(year_number, month_number, day_number).isocalendar()[1]\n",
    "        total_traffic_per_week[week_number] += hour_datapoint[6] #add traffic that hour to the total traffic per day\n",
    "    return total_traffic_per_week\n",
    "\n",
    "#generate lists of total traffic per day for the years\n",
    "total_traffic_per_week_2016 = get_total_traffic_per_week(year_2016)\n",
    "total_traffic_per_week_2017 = get_total_traffic_per_week(year_2017)\n",
    "total_traffic_per_week_2018 = get_total_traffic_per_week(year_2018)\n",
    "total_traffic_per_week_2019 = get_total_traffic_per_week(year_2019)\n",
    "\n",
    "\n",
    "x_value_weeks_total = list(range(0, len(total_traffic_per_week_2016)))\n",
    "\n",
    "#plotting the traffic pr day\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(x_value_weeks_total,total_traffic_per_week_2016, 'r-', alpha = 0.7, label = \"2016\")\n",
    "plt.plot(x_value_weeks_total,total_traffic_per_week_2017, 'b-', alpha = 0.7, label = \"2017\")\n",
    "plt.plot(x_value_weeks_total,total_traffic_per_week_2018, 'g-', alpha = 0.7, label = \"2018\")\n",
    "plt.plot(x_value_weeks_total,total_traffic_per_week_2019, 'y-', alpha = 0.7, label = \"2019\")\n",
    "\n",
    "# Marking seasonal holidays\n",
    "plt.axvline(x=9, ymin=0, ymax=60000, color = 'k',alpha = 0.6)\n",
    "plt.text(9.1,0,'Winter holiday')\n",
    "plt.axvline(x=41, ymin=0, ymax=60000, color = 'k', alpha = 0.6)\n",
    "plt.text(41.1,0,'Autumn holiday')\n",
    "plt.axvline(x=52, ymin=0, ymax=60000, color = 'k', alpha = 0.6)\n",
    "plt.text(52.1,0,'Christmas holiday')\n",
    "plt.axvline(x=29, ymin=0, ymax=60000, color = 'k', alpha = 0.6)\n",
    "plt.text(29.1,0,'Summer holiday')\n",
    "\n",
    "# Marking easter holidays\n",
    "plt.axvline(x=12, ymin=0, ymax=60000, color = 'r', alpha = 0.4)\n",
    "plt.axvline(x=13, ymin=0, ymax=60000, color = 'g', alpha = 0.4)\n",
    "plt.axvline(x=15, ymin=0, ymax=60000, color = 'b', alpha = 0.4)\n",
    "plt.axvline(x=16, ymin=0, ymax=60000, color = 'y', alpha = 0.4)\n",
    "plt.text(16.1,0,'Easter holidays')\n",
    "\n",
    "# Marking outlier\n",
    "plt.axvline(x=38, ymin=0, ymax=60000, color = 'c', alpha = 0.4)\n",
    "plt.text(38.1, 0, \"2017 UCI Road World Championships\", rotation = \"90\")\n",
    "# Marking outlier\n",
    "plt.axvline(x=25, ymin=0, ymax=60000, color = 'c', alpha = 0.4)\n",
    "plt.text(25.1, 0, \"Missing data\", rotation = \"90\")\n",
    "\n",
    "\n",
    "# Adding labels\n",
    "plt.xticks(np.arange(min(x_value_weeks_total), max(x_value_weeks_total)+1, 1))\n",
    "plt.xlabel(\"Week of the year\")\n",
    "plt.ylabel(\"Total traffic per day\")\n",
    "plt.title(\"Total traffic per week\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The black vertical lines represent condistent holidays that appear to fall on the same time every year. Unfortunately easter falls on different weeks every year, but we will mark then as \"holiday\" too. There is some data missing around week 25, but this has no effect even though it looks like it on the graph. Had the graph represented \"average traffic per week\" there would be no dip in traffic. \n",
    "\n",
    "In week 38 in 2017, however, there was a big sports event in Bergen, so this is a true outlier which will have an effect on the model.\n",
    "\n",
    "Overall we can see that the week number has a lot to say for the fluctuation of data, so we could add it to the list of features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weekdays_to_SNTR = [0]*7\n",
    "weekdays_to_DNP = [0]*7\n",
    "weekdays_total = [0]*7\n",
    "is_weekend = []\n",
    "\n",
    "for i in range(len(traffic_data)):\n",
    "    data_point = traffic_data.iloc[i]\n",
    "    weekday = traffic_data_datetime[i].weekday()\n",
    "    is_weekend.append(int(weekday > 4))  # Adding to one-hot \"isWeekend\"\n",
    "    weekdays_to_SNTR[weekday] += data_point[4]\n",
    "    weekdays_to_DNP[weekday] += data_point[5]\n",
    "    weekdays_total[weekday] += data_point[6]\n",
    "\n",
    "print(weekdays_to_SNTR)\n",
    "print(weekdays_to_DNP)\n",
    "print(weekdays_total)\n",
    "\n",
    "day_names = list(calendar.day_name)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(day_names, weekdays_to_DNP, c = 'r', label =\"From city center\")\n",
    "plt.plot(day_names, weekdays_to_SNTR, c = 'g', label = \"To city center\")\n",
    "plt.title(\"Mean traffic per weekday to and from city center\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "day_names = list(calendar.day_name)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(day_names, weekdays_total, label =\"Total traffic\")\n",
    "plt.title(\"Mean traffic per weekday in total\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#TODO: implement one-hot encoding for months and days. Those values have very little to do with each other"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Now let us look at the traffic for each hour of the day, and compare the traffic in and out of town\n",
    "\n",
    "def get_total_traffic_per_hour_of_day(string_label):\n",
    "    y_per_hour = np.zeros(24)\n",
    "    for i in range(0, 23):\n",
    "        traffic_per_hour_i = traffic_data[traffic_data['Fra_time'] == i]\n",
    "        mean_pr_hour = np.mean(traffic_per_hour_i[string_label])\n",
    "        y_per_hour[i] = mean_pr_hour\n",
    "    return y_per_hour\n",
    "\n",
    "y_total_per_hour = get_total_traffic_per_hour_of_day('Volum totalt')\n",
    "y_to_DNP_per_hour = get_total_traffic_per_hour_of_day('Volum til DNP')\n",
    "y_to_SNTR_per_hour = get_total_traffic_per_hour_of_day('Volum til SNTR')\n",
    "\n",
    "x_hour_number = list(range(0, 24))\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(x_hour_number,y_total_per_hour, label =\"Total traffic\")\n",
    "plt.plot(x_hour_number,y_to_DNP_per_hour, c = 'r', label =\"From city center\")\n",
    "plt.plot(x_hour_number,y_to_SNTR_per_hour, c = 'g', label = \"To city center\")\n",
    "plt.title(\"Mean traffic per hour of the day\")\n",
    "plt.xticks(np.arange(min(x_hour_number), max(x_hour_number)+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering\n",
    "\n",
    "### Holiday"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Adding holiday feature to data #####\n",
    "\n",
    "#First we want to make a list of days that we define as \"holiday days\". We will base this on the holidays identified in the graph above.\n",
    "holiday_dates = []\n",
    "\n",
    "#Some helper functions\n",
    "def getDateRangeFromWeek(p_year,p_week): #sauce: http://mvsourcecode.com/python-how-to-get-date-range-from-week-number-mvsourcecode/\n",
    "    firstdayofweek = datetime.datetime.strptime(f'{p_year}-W{int(p_week )- 1}-1', \"%Y-W%W-%w\").date()\n",
    "    lastdayofweek = firstdayofweek + datetime.timedelta(days=6.9)\n",
    "    return firstdayofweek, lastdayofweek\n",
    "\n",
    "def extract_holiday_dates(holdiday_year, holiday_week): #sauce: https://stackoverflow.com/questions/7274267/print-all-day-dates-between-two-dates\n",
    "    holiday_dates = np.full(7, datetime_representation_of_today) #initialize list to store holiday dated\n",
    "    firstdate, lastdate =  getDateRangeFromWeek(holdiday_year,holiday_week)\n",
    "    delta =  lastdate - firstdate       # as timedelta\n",
    "    for i in range(delta.days + 1):\n",
    "        holiday_day = firstdate + timedelta(days=i)\n",
    "        holiday_dates[i] = holiday_day\n",
    "    return holiday_dates\n",
    "\n",
    "# The week number of holidays is based on information from Bergen Kommune, timeanddate.no and the graph above\n",
    "winter_holiday_week_number = 9\n",
    "summer_holiday_week_number_range = list(range(26, 33))\n",
    "autumn_holiday_week_number = 41\n",
    "christmas_holiday_week_number_range = list(range(52, 54))\n",
    "\n",
    "# Add the holiday dates for years 2015-2019\n",
    "for year in range(2015, 2020):\n",
    "    winter_holiday_dates = extract_holiday_dates(year, winter_holiday_week_number)\n",
    "    autumn_holiday_dates = extract_holiday_dates(year, autumn_holiday_week_number)\n",
    "\n",
    "    summer_holiday_dates = []\n",
    "    for week in summer_holiday_week_number_range:\n",
    "        new_summer_holiday_dates = extract_holiday_dates(year, week)\n",
    "        summer_holiday_dates = np.concatenate([summer_holiday_dates, new_summer_holiday_dates])\n",
    "\n",
    "    christmas_holiday_dates = []\n",
    "    for week in christmas_holiday_week_number_range:\n",
    "        new_christmas_holiday_dates = extract_holiday_dates(year, week)\n",
    "        christmas_holiday_dates = np.concatenate([christmas_holiday_dates, new_christmas_holiday_dates])\n",
    "\n",
    "    holiday_dates = np.concatenate([holiday_dates, winter_holiday_dates, summer_holiday_dates, autumn_holiday_dates, christmas_holiday_dates]) # add holiday dates for the year\n",
    "\n",
    "holiday_dates = np.concatenate([holiday_dates,\n",
    "[datetime.date(2015, 12, 28), datetime.date(2015, 12, 29), datetime.date(2015, 12, 30),\n",
    " datetime.date(2015, 12, 31), datetime.date(2016, 1, 1), datetime.date(2016, 12, 26),\n",
    " datetime.date(2016, 12, 27), datetime.date(2016, 12, 28), datetime.date(2016, 12, 29),\n",
    " datetime.date(2016, 12, 30), datetime.date(2016, 12, 31), datetime.date(2017, 1, 1),\n",
    " datetime.date(2018, 1, 1), datetime.date(2018, 12, 31), datetime.date(2019, 1, 1),\n",
    " datetime.date(2019, 12, 30), datetime.date(2019, 12, 31)]])\n",
    "\n",
    "# Add the easter weeks separately, as the week of the holiday varies from year to year\n",
    "holiday_dates = np.concatenate([holiday_dates, \n",
    "                                extract_holiday_dates(2016, 13), # dates for easter 2016\n",
    "                                extract_holiday_dates(2017, 16), # dates for easter 2017\n",
    "                                extract_holiday_dates(2018, 14), # dates for easter 2018\n",
    "                                extract_holiday_dates(2019, 16)]) # dates for easter 2019\n",
    "\n",
    "\n",
    "#Now we have a list of holiday dates, and can generate a hot-one encoded feature array for the dataset.\n",
    "\n",
    "is_holiday = np.zeros(len(traffic_data)) #Feature array for holidays. 1 if the datapoint is in a holiday, 0 otherwise\n",
    "\n",
    "#This is a brute force method, which definitely could be improved upon\n",
    "for i in range(len(traffic_data_datetime)):\n",
    "    for holiday_date in holiday_dates:\n",
    "        if traffic_data_datetime[i].date() == holiday_date:\n",
    "            is_holiday[i] = 1\n",
    "            continue\n",
    "\n",
    "traffic_data['is_holiday'] = is_holiday #add \"is_holiday\" column to traffic_data dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to convey the cyclic nature of the hours of the day, and unfortunately the way the hours are represented now gives no indication that the 23rd hour is close to the 0th hour. To solve this we will use two triginometric functions sin((2t*pi)/24) and sin((2t*pi)/24), where t is the hour of the day. We add two features one with sin and the other with cos, because if we only used one of the two, then two hours in the day would have the exact same value, indicating a relationship where there is none.\n",
    "\n",
    "We do the same with days of the year.\n",
    "\n",
    "### Cyclical nature of hours and days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sin_cos_for_cycical_values(traffic_data_datetime_input, cycle_size, hour_cycle):\n",
    "    #first we generate a list values for the two functions, so we can just retrieve the values instead of calculate them each time.\n",
    "    sin_values = np.ones(cycle_size)\n",
    "    cos_values = np.ones(cycle_size)\n",
    "    # fill in lists of sin and cos values\n",
    "    for t in range(cycle_size):\n",
    "        sin_values[t] = np.sin((2*t*np.pi) / cycle_size)\n",
    "        cos_values[t] = np.cos((2*t*np.pi) / cycle_size)\n",
    "    \n",
    "    #initialize new feature columns\n",
    "    sin_feature = np.zeros(len(traffic_data_datetime_input)) \n",
    "    cos_feature = np.zeros(len(traffic_data_datetime_input))\n",
    "    #Iterate through all the data, and add the correspongind sin and cos values to the feature columns\n",
    "    for i in range(len(traffic_data_datetime_input)):\n",
    "        # retrieve either hour or day number\n",
    "        if (hour_cycle and cycle_size == 24):\n",
    "            cyclical_number_of_datapoint = traffic_data_datetime_input[i].hour\n",
    "        elif(not(hour_cycle) and cycle_size == 367):\n",
    "            cyclical_number_of_datapoint = traffic_data_datetime_input[i].timetuple().tm_yday\n",
    "        else:\n",
    "            print(\"Invalid cycle size:\", cycle_size)\n",
    "            print(\"TOOOOO\")\n",
    "            return\n",
    "        sin_feature[i] = sin_values[cyclical_number_of_datapoint]\n",
    "        cos_feature[i] = cos_values[cyclical_number_of_datapoint]\n",
    "    return sin_feature, cos_feature\n",
    "        \n",
    "traffic_data['sin_hour'], traffic_data['cos_hour'] = sin_cos_for_cycical_values(traffic_data_datetime, 24, True)\n",
    "traffic_data['sin_day'], traffic_data['cos_day'] = sin_cos_for_cycical_values(traffic_data_datetime, 367, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Daylight saving time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traffic_data['is_weekend'] = is_weekend #add \"is_weekend\" column to traffic_data dataframe\n",
    "#DST = daylight saving time\n",
    "#Generate a column for the DST feature, with 1 indicating the datapoint is in DST, and 0 if it is not\n",
    "DST = []\n",
    "DST_switch = False\n",
    "for i in range(len(traffic_data)):\n",
    "    data_point = traffic_data.iloc[i]\n",
    "    # TODO: Abstract/refactor the line under\n",
    "    if data_point[0] == 2016 and data_point[1] == 3 and data_point[2] == 27 and data_point[3] == 2:\n",
    "        DST_switch = True\n",
    "    elif data_point[0] == 2016 and data_point[1] == 10 and data_point[2] == 30 and data_point[3] == 3:\n",
    "        DST_switch = False\n",
    "    elif data_point[0] == 2017 and data_point[1] == 3 and data_point[2] == 26 and data_point[3] == 2:\n",
    "        DST_switch = True\n",
    "    elif data_point[0] == 2017 and data_point[1] == 10 and data_point[2] == 29 and data_point[3] == 3:\n",
    "        DST_switch = False\n",
    "    elif data_point[0] == 2018 and data_point[1] == 3 and data_point[2] == 25 and data_point[3] == 2:\n",
    "        DST_switch = True\n",
    "    elif data_point[0] == 2018 and data_point[1] == 10 and data_point[2] == 28 and data_point[3] == 3:\n",
    "        DST_switch = False\n",
    "    elif data_point[0] == 2019 and data_point[1] == 3 and data_point[2] == 31 and data_point[3] == 2:\n",
    "        DST_switch = True\n",
    "    elif data_point[0] == 2019 and data_point[1] == 10 and data_point[2] == 27 and data_point[3] == 3:\n",
    "        DST_switch = False\n",
    "    DST.append(int(DST_switch))\n",
    "\n",
    "traffic_data['is_DST'] = DST #add DST column to traffic_data dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model selection\n",
    "\n",
    "We will be evaluating some models and selecting the most appropriate for:\n",
    "- Predicting TOTAL traffic volume\n",
    "- Predicting traffic TO city center\n",
    "- Predicting traffic FROM city center\n",
    "\n",
    "These models will be named TOTAL, TO and FROM respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection for predicting TOTAL traffic volume\n",
    "\n",
    "### Baseline using linear regression -TOTAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random forests -TOTAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use TimeSeriesSplit to split the data into train and test to get accuracies\n",
    "X = traffic_data[[\"År\", \"Måned\", \"Dag\", \"Fra_time\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"is_holiday\", \"is_weekend\", \"is_DST\"]].values\n",
    "y = traffic_data[\"Volum totalt\"].values\n",
    "#Split data into train_val and test data. Do not shuffle the data as it is timeseries data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "number_of_splits = 5\n",
    "tscv = TimeSeriesSplit(number_of_splits)\n",
    "\n",
    "\n",
    "print(\"###\\tRandom Forest\\t###\\nTotal number of splits:\", number_of_splits)\n",
    "split_number = 1\n",
    "\n",
    "list_of_coefficients_of_determination = [] #list to keep track of coefficients of determination\n",
    "for train_index, val_index in tscv.split(X_train_val):\n",
    "    print(\"Split number:\", split_number)\n",
    "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "    y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "    forest = ens.RandomForestRegressor()\n",
    "    forest.fit(X_train,  y_train)\n",
    "    forest_predict = forest.predict(X_val) \n",
    "    #forest_MSE = mean_squared_error(y_test, forest_predict)\n",
    "    print(\"Mean Absolute Error: %.2f\" %mean_absolute_error(y_val, forest_predict))\n",
    "    coefficient_of_determination = r2_score(y_val, forest_predict)\n",
    "    list_of_coefficients_of_determination.append(coefficient_of_determination)\n",
    "    print('Coefficient of determination: %.2f' %coefficient_of_determination)\n",
    "    split_number += 1    \n",
    "    print(\"\")\n",
    "print('Mean coefficient of determination: %.2f' %np.mean(list_of_coefficients_of_determination)) #might  be some sklearn function that does this for us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression decision tree - TOTAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\\n###\\tRegression Decision Tree\\t###\\nTotal number of splits:\", number_of_splits)\n",
    "best_mean_coeff_det = -1\n",
    "best_mean_coeff_det_n = 0\n",
    "for i in range(1, 30):\n",
    "    split_number = 1\n",
    "    list_of_coefficients_of_determination = [] #list to keep track of coefficients of determination\n",
    "    for train_index, val_index in tscv.split(X_train_val):\n",
    "        #print(\"Split number:\", split_number)\n",
    "        X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "        y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "        tree = DecisionTreeRegressor(max_depth=i)\n",
    "        tree.fit(X_train,  y_train)\n",
    "        tree_predict = tree.predict(X_val)\n",
    "        #tree_MSE = mean_squared_error(y_test, tree_predict)\n",
    "        #print(\"Mean Absolute Error: %.2f\" %mean_absolute_error(y_val, tree_predict))\n",
    "        coefficient_of_determination = r2_score(y_val, tree_predict)\n",
    "        list_of_coefficients_of_determination.append(coefficient_of_determination)\n",
    "        print('Coefficient of determination: %.2f' %coefficient_of_determination)\n",
    "        split_number += 1\n",
    "        print(\"\")\n",
    "    print(\"Max tree depth\", i)\n",
    "    mean_coeff_det = np.mean(list_of_coefficients_of_determination)\n",
    "    if mean_coeff_det > best_mean_coeff_det:\n",
    "        best_mean_coeff_det = mean_coeff_det\n",
    "        best_mean_coeff_det_n = i\n",
    "    print('Mean coefficient of determination: %.2f\\n\\n' %mean_coeff_det) #might  be some sklearn function that does this for us\n",
    "print(\"Best max depth is\", best_mean_coeff_det_n, 'with Mean coefficient of determination: %.2f' %best_mean_coeff_det)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural network - TOTAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n\\n###\\tNeural Network\\t###\\nTotal number of splits:\", number_of_splits)\n",
    "\n",
    "norm_td=(traffic_data-traffic_data.min())/(traffic_data.max()-traffic_data.min()) #TODO: experimental\n",
    "X = norm_td[[\"År\", \"Måned\", \"Dag\", \"Fra_time\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"is_holiday\", \"is_weekend\", \"is_DST\"]].values\n",
    "y = norm_td[\"Volum totalt\"].values\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "split_number = 1\n",
    "\n",
    "list_of_coefficients_of_determination = [] #list to keep track of coefficients of determination\n",
    "for train_index, val_index in tscv.split(X_train_val):\n",
    "    print(\"Split number:\", split_number)\n",
    "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "    y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "    # Optimal number of neurons should be between 300 and 1500 (one layer is enough, apparently)\n",
    "    nn = MLPRegressor(hidden_layer_sizes=(90, 90, 90, 90, 90, 90, 90, 90), random_state=1, max_iter=400)  # Default Relu with Adam cost optimizer\n",
    "    nn.fit(X_train,  y_train)\n",
    "    nn_predict = nn.predict(X_val)\n",
    "    #nn_MSE = mean_squared_error(y_test, nn_predict)\n",
    "    print(\"Mean Absolute Error: %.4f\" %mean_absolute_error(y_val, nn_predict))\n",
    "    coefficient_of_determination = r2_score(y_val, nn_predict)\n",
    "    list_of_coefficients_of_determination.append(coefficient_of_determination)\n",
    "    print('Coefficient of determination: %.4f' %coefficient_of_determination)\n",
    "    split_number += 1\n",
    "    print(\"\")\n",
    "print('Mean coefficient of determination: %.4f' %np.mean(list_of_coefficients_of_determination)) #might  be some sklearn function that does this for us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing of selected model for predicting TOTAL traffic volume"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: test selected model w testdata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection for predicing traffic TO city center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: same as with total volume, just with other traffic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline with linear regression - TO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random forests - TO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression trees - TO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural networks - TO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing of selected model for predicting traffic TO city center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict traffic TO city center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random forests - FROM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression trees - FROM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neural networks - FROM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing of selected model for predicting traffic FROM city center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict traffic FROM city center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "## Differneces in predicting traffic TO and FROM city center\n",
    "TODO: write"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance of models on 2020 data\n",
    "\n",
    "To test the perfomance of our trained models on 2020 data, we will first feature engineer our 2020 data in the same we as we did previously, and thereafter use it as test data to evaluate our TOTAL, TO and FROM models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traffic_data_2020 = pd.read_csv(\"data_2020.csv\")\n",
    "\n",
    "#Generate datetime array for 2020 traffic data\n",
    "traffic_data_2020_datetime = generate_datetime_array_from_traffic_data(traffic_data_2020)\n",
    "\n",
    "traffic_data_2020['sin_hour'], traffic_data_2020['cos_hour'] = sin_cos_for_cycical_values(traffic_data_2020_datetime, 24, True)\n",
    "traffic_data_2020['sin_day'], traffic_data_2020['cos_day'] = sin_cos_for_cycical_values(traffic_data_2020_datetime, 367, False)\n",
    "\n",
    "print(traffic_data_2020)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Regression Decision Tree\n",
    "days = 60\n",
    "hours = days * 24\n",
    "x = traffic_data[[\"År\", \"Måned\", \"Dag\", \"Fra_time\", \"is_weekend\", \"is_DST\"]].values\n",
    "y = traffic_data[\"Volum totalt\"].values\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=10)\n",
    "tree.fit(x, y)\n",
    "\n",
    "test_1 = traffic_data[[\"År\", \"Måned\", \"Dag\", \"Fra_time\", \"is_weekend\", \"is_DST\"]].values[hours:2*hours]\n",
    "result_1 = tree.predict(test_1)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "x_hour = list(range(hours))\n",
    "plt.plot(x_hour, result_1)\n",
    "plt.scatter(x_hour, traffic_data[\"Volum totalt\"].values[hours:2*hours])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}